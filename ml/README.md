# MLディレクトリ概要

## プロジェクトの目的
このディレクトリは、first-aiプロジェクトの機械学習（ML）部分の開発・実験・管理を行うためのものです。

## データ
- `data/` ディレクトリに学習・評価用データセットを配置します。
- データの前処理や分析もここで行います。

## コード
- `src/` ディレクトリに前処理、モデル学習、推論、評価などのPythonコードを配置します。
- Kaggleで作成した複数のモデルを管理・選択できるようにするため、以下の手順で移行します：
  1. Kaggle Notebookを`.py`または`.ipynb`形式でダウンロード
  2. 必要なライブラリの依存関係を`requirements.txt`に記載
  3. データセットは`data/`ディレクトリに配置
  4. コードは`src/models/`ディレクトリに配置し、各モデルごとにサブディレクトリを作成
  5. 各モデルの設定ファイル（ハイパーパラメータ等）を`config/`ディレクトリに配置
  6. モデル選択用のインターフェースクラスを作成し、`src/inference.py`に実装
- Jupyter Notebookやスクリプトもここに置いてOKです。

## モデル
- 学習済みモデルの保存場所や、モデルのバージョン管理方法もここで管理します。

## モデルの追加方法
1. `src/models/`配下に新しいモデル用のサブディレクトリを作成し、学習済みモデル（例: `your_model.joblib`）を保存します。
2. `src/inference.py`の`ModelSelector`クラスの`self.models`に、モデル名と保存パスを追加します。
   例：
   ```python
   self.models = {
       'sample': 'src/models/sample_model/sample_model.joblib',
       'your_model': 'src/models/your_model/your_model.joblib',
   }
   ```
3. 必要に応じて`config/`に設定ファイルを追加します。

## 推論APIについて
- `ml/backend_api.py`のAPIは**全モデル共通**で利用できます。
- モデルごとにAPIを分ける必要はありません。`model_name`で切り替えます。
- 例：
  ```json
  {
    "model_name": "sample",
    "input_data": [[1.0, 2.0, 3.0, 4.0]]
  }
  ```
  のようにリクエストすれば、`sample`モデルで推論されます。

## 多様な入力データへの対応
- 本プロジェクトは**表形式データ・画像・テキストなど様々な入力データ**に対応可能です。
- モデルごとに「入力データの前処理」と「推論処理」を分けて実装することで、柔軟に拡張できます。
- APIのリクエスト形式も、モデルごとに適した形（数値配列・Base64画像・テキストなど）で設計できます。
- 例：
  - 表形式データ：2次元配列（list of list）
  - 画像：Base64文字列やバイナリ
  - テキスト：文字列

## Kaggle等から持ち込んだコードを動かすために必要な作業
Kaggle Notebook等で作成したコードを本プロジェクトに移植して動作させるには、以下の作業が必要です。

1. **必要なファイルの整理**
   - Notebookやスクリプトを`src/models/モデル名/`ディレクトリに配置
   - 学習済みモデルファイル（例: `.pkl`, `.joblib`）も同ディレクトリに保存
2. **依存ライブラリの追加**
   - 使用しているライブラリを`requirements.txt`に追記
3. **データパスの修正**
   - Kaggle特有のパスやファイル名を、`data/`配下のパスに書き換え
4. **前処理・推論部分の関数化**
   - Notebookのセルを「前処理」「学習」「推論」など関数単位に整理
   - 推論用の関数（例: `predict(input_data)`）を用意
5. **ModelSelectorへの登録**
   - `src/inference.py`の`ModelSelector`にモデル名とパスを追加
6. **設定ファイルの追加（必要に応じて）**
   - ハイパーパラメータ等を`config/`に保存
7. **APIで利用する場合は入力形式を合わせる**
   - APIの`input_data`形式に合わせて、前処理やデータ変換を実装

> **ポイント**：KaggleのNotebookを「そのまま」ではなく、上記のように整理・関数化・パス修正を行うことで、プロジェクト内で再利用・API化しやすくなります。

## 今後の開発ステップ（例）
1. 要件・目的の明確化
2. データの収集・前処理
3. モデルの設計・学習
4. 推論用コードの作成
5. バックエンドAPIとの連携（推論関数の整備）
6. ドキュメントの充実

## バックエンドとの連携方針
- 必要に応じて、`backend`から`ml/src`の推論用関数やクラスをimportして利用します。
- 連携方法やAPI仕様はこのREADMEにも追記していきます。

## アプリ全体の最新概要
- 本アプリは「タスク（例：数値分類・画像分類・テキスト分類）」を選択するだけで、入力UIや内部で使うモデルが自動的に切り替わる実践的な構成です。
- ユーザーは「どのモデルを使うか」を意識する必要はありません。
- タスクごとに最適な入力形式（数値配列・画像アップロード・テキスト入力など）が自動で表示されます。
- バックエンドでは`task_name`に応じて適切なモデルや処理を自動選択し、推論結果を返します。
- 今後タスクやモデルを追加する場合も、タスク名と処理・モデルの紐付けを追加するだけで拡張できます。

---

このREADMEはML部分の設計・運用方針や進捗を明確化するために活用してください。

- `config/` 各モデルの設定ファイル（ハイパーパラメータ等）を配置します。 